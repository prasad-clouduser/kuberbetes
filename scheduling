
1. the scheduler goes through all the pods and looks for thse that dont have this project node set. 
2. those are candiate for scheudling. 
3. then identify the right node to schedule on using scheduling algarithm. 

Without scheduler the easiest way to schedule a POD is to simply set the node name field to name of the node in yoru pod speecification file .
k8s won't allow you to modify the node name property of the pod (pod already running but no node) 

You can create a binding object and do a post request to a running pod. (convert the binding object yaml to JSON format) 
if no scheduler is there, pod will be in pending state always. 

===================================================================================================

labels & selectors: 

inorder to connect the replica set to the POD we configure the selector field under the replica set specification to match the labels defined on the POD. 
Mention other labels also to make sure that right pods are discovered by the replica set. single label will do the job.
on creation if labels match the replica set is created successfully. 

annotations are used to record other details for informatory purposes. 
like tool details like name, version, build information etc or contact details or phonenumbers, email IDs etc. 
that may be used for some kind of integration purposes. 

====================================================================================================

TAINTS and Tolerations: 
consider Node A is tainted: 

1. by default PODs have no tolerations. 
2. Non of the pod can tolerate any taint. 
3. We would like to allow only pod D to be on Node A, so we add a toleration to POD D. 
4. when scheduler tries to place the pods on Node A, it goes thorough. Node A accepts the pods that tolerate the taint Blue. 

taint-effect: what would happen to the POD if they don't tolerate the taint. 
taint and tolerations are meant accept pods with tolerations only, the pod can be placed on other nodes as well as there is no taint for other nodes. 

when k8s cluster is first setup a taint is set on the master node automatically that prevents any pods from being scheduled on this node. that is why scheduler never
schedule pods on the master node. 

==============================================================================================================

Node Selectors: 

if you want to place the POD on a specific node NODE A you can use node selector. suppose data processing POD on the larger node. scheduler based on the labels of node it decides to 
schedule pod on the node. This does not complex operations like NotIN, exists, In 

===============================================================================================================

Node affinity: 
what if someone changes the label on the node at future point in time? will the pod continue to stay on the node ? answered by long sentence. 

type of the node affinity defines the behaviour of the scheduler with respect to node affinity and stages in the life cycle of the pod. 

========================================================================================================================================

If nodes have no suffient resources available, the scheduler avoids placing the pod on those nodes and instead places the pod on one where suffient resources are available. 
so min amount of CPU and Memory requested by the container is resource request. when the scheduler tries to place pod on a node it uses these num to identify the node 
which has suffient amount of resources available. 

by default a container has no limit to the resources it can consume on a node. 
However you can set a limit for the resource usage on these pods. 

what happens if pod exceeds the limit of CPU mentioned in spec? in case of system throttles CPu so that it does not go beyond the specified limit. 
a container can't use more cpu resources than its limit. 
A container can use more memory than its limit. but throws OOM exception 

Requests and No limits Scenrio: 

1. any POD can consume as many cpu cycles as available. at any point of in time if POD 2 requires additional CPU cycles or whatever it has requested it will be guranteed its requested CPU cycle. 
but memory case we can gurantee by killing the first pod. because memory can't be throttled

=================================================
Deamon Set: 

for v1.12 - uses NodeAffinity and default scheduler to schedule pods on nodes. 
on eacch pod set the node property to bypass the scheduler and get the pod scheduled on node directly. (default behaviour of daemon set till 1.12) 

=====================================================
Static pods: 
PODs that are created by the kubelet on its own, without the intervention of the API server or rest of the k8s cluster components are known as static pods. 
place the manifest files in /etc/kubernetes/manifests -> kubelet periadically reads from here. 
kubectl works at the pod level, other components can not be created. 

static pod -> this is how kubeadmin tool setup the cluster. all control plan components can be deplyed as static pods. 

=========================================

default scheduler: 
it has an algarithm that distributes the pods across evenly as well as takes into consideration various conditions we specify through taints and tolerations 
and node affinity etc. 

what if you want to perform additonal checks, want to place the components of app on nodes after perfoming addtional checks. 
/etc/kubernetes/my-scheduler/my-scheduler-config.yaml --> custom scheduler config which need to be specified in deployment. 
This config file can be passed as configmap, passed as volumeMounts to containers. 

we can instruct k8s to use custom scheduler instead of default scheduler. 

kubectl get events -o wide -> fidn out events in current namespace which scheduler picked up
